{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "881fe14f-e758-4108-bc95-c0cb75361b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import bioframe \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import json\n",
    "from io import StringIO\n",
    "\n",
    "import akita_utils \n",
    "import pysam\n",
    "import h5py\n",
    "genome_open = pysam.Fastafile('/project/fudenber_735/genomes/mm10/mm10.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "40a0bf0d-860a-4b3c-9ef9-13dd4f319b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n",
      "built\n",
      "restored\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(512, 130305, (130305,))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import pysam\n",
    "from basenji import dataset, seqnn, dna_io,stream\n",
    "head_i = 1 #mouse\n",
    "model_num = 1 #which fold to use\n",
    "\n",
    "base_dir = '/project/fudenber_735/tensorflow_models/akita/v2/models/'\n",
    "model_dir = base_dir+\"/f\"+str(model_num)+\"c0/train/\"\n",
    "model_file  = model_dir+'/model'+str(head_i)+'_best.h5'\n",
    "\n",
    "params_file = model_dir+'/params.json'\n",
    "with open(params_file) as params_open:\n",
    "    params = json.load(params_open)\n",
    "    params_model = params['model']\n",
    "    params_train = params['train']\n",
    "seq_length = params_model['seq_length']\n",
    "params_model['verbose'] = False\n",
    "seqnn_model = seqnn.SeqNN(params_model)\n",
    "print('built')\n",
    "seqnn_model.restore(model_file, head_i=head_i)\n",
    "print('restored')\n",
    "\n",
    "hic_diags = params_model['diagonal_offset']\n",
    "try:\n",
    "    target_crop = params_model['trunk'][-2]['cropping']\n",
    "except:\n",
    "    target_crop = params_model['target_crop']\n",
    "target_length_cropped = int((seq_length//2048 - target_crop*2 - hic_diags)* ((seq_length//2048 - target_crop*2 - hic_diags) +1)/2) \n",
    "target_map_size = seq_length//2048  - target_crop*2 \n",
    "triu_tup = np.triu_indices(target_map_size,2)\n",
    "target_map_size, target_length_cropped, triu_tup[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d71294a-57f4-4dbb-a042-598f19e62497",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'akita_utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m site_df \u001b[38;5;241m=\u001b[39m \u001b[43makita_utils\u001b[49m\u001b[38;5;241m.\u001b[39mprepare_insertion_tsv(\n\u001b[1;32m      2\u001b[0m     h5_dirs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/project/fudenber_735/tensorflow_models/akita/v2/analysis/permute_boundaries_motifs_ctcf_mm10_model*/scd.h5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     score_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCD\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     flank_pad \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m, \u001b[38;5;66;03m#how much flanking sequence around the sites to include\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     weak_thresh_pct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# don't use sites weaker than this, might be artifacts\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     weak_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m ,\n\u001b[1;32m      7\u001b[0m     strong_thresh_pct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m99\u001b[39m, \u001b[38;5;66;03m# don't use sites weaker than this, might be artifacts\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     strong_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m ,\n\u001b[1;32m      9\u001b[0m     save_tsv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# optional filename to save a tsv\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m num_seqs \u001b[38;5;241m=\u001b[39m site_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'akita_utils' is not defined"
     ]
    }
   ],
   "source": [
    "site_df = akita_utils.prepare_insertion_tsv(\n",
    "    h5_dirs = '/project/fudenber_735/tensorflow_models/akita/v2/analysis/permute_boundaries_motifs_ctcf_mm10_model*/scd.h5',\n",
    "    score_key = 'SCD',\n",
    "    flank_pad = 60, #how much flanking sequence around the sites to include\n",
    "    weak_thresh_pct = 1, # don't use sites weaker than this, might be artifacts\n",
    "    weak_num = 5 ,\n",
    "    strong_thresh_pct = 99, # don't use sites weaker than this, might be artifacts\n",
    "    strong_num = 5 ,\n",
    "    save_tsv=None, # optional filename to save a tsv\n",
    ")\n",
    "num_seqs = site_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03fb1cd-4243-4e91-ab8c-ca9710580a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 1\n",
    "batch_size = 6\n",
    "shuffle_k = 8\n",
    "\n",
    "## alternate approach, figure out a way to nicely use the whole JASPAR motif\n",
    "# motif_file = '/project/fudenber_735/motifs/pfms/JASPAR2022_CORE_redundant_pfms_jaspar/MA0139.1.jaspar'\n",
    "# motif = read_jaspar_to_numpy(motif_file)\n",
    "### using just the core motif and this shuffling which also makes the reverse complement a low score works well\n",
    "mot = '>CCAsyAGrkGGCr\\n0.0000\\t1.0000\\t0.0000\\t0.0000\\n0.0000\\t1.0000\\t0.0000\\t0.0000\\n1.0000\\t0.0000\\t0.0000\\t0.0000\\n0.0000\\t0.5000\\t0.5000\\t0.0000\\n0.0000\\t0.5000\\t0.0000\\t0.5000\\n1.0000\\t0.0000\\t0.0000\\t0.0000\\n0.0000\\t0.0000\\t1.0000\\t0.0000\\n0.5000\\t0.0000\\t0.5000\\t0.0000\\n0.0000\\t0.0000\\t0.5000\\t0.5000\\n0.0000\\t0.0000\\t1.0000\\t0.0000\\n0.0000\\t0.0000\\t1.0000\\t0.0000\\n0.0000\\t1.0000\\t0.0000\\t0.0000\\n0.5000\\t0.0000\\t0.5000\\t0.0000'\n",
    "motif = pd.read_csv(StringIO(mot),sep='\\t',header=0, names=['A','C','G','T']).values\n",
    "motif_window = int(np.ceil(len(motif)/2))\n",
    "mot_shuf = np.array([12,0,1,11,10,3,2,8,9,4,5,7,6]) \n",
    "\n",
    "ctcf_thresh = 8\n",
    "scores_thresh = 5500\n",
    "scores_pixelwise_thresh = .04\n",
    "\n",
    "\n",
    "\n",
    "flat_seqs = []\n",
    "for ind in range(num_seqs):\n",
    "    print(ind)\n",
    "    chrom, start, end, strand = site_df.iloc[ind][['chrom','start_2','end_2','strand_2']]\n",
    "    mid = int(.5 * (start +end))\n",
    "    start, end =  mid - seq_length//2 , mid + seq_length//2\n",
    "    seq = genome_open.fetch(chrom, start, end).upper()\n",
    "    #if strand == '-': seq = dna_rc(seq)\n",
    "    seq_1hot = dna_io.dna_1hot(seq)\n",
    "\n",
    "    num_iters = 0\n",
    "    while num_iters < max_iters:\n",
    "        print('ind',ind, ', iter ',num_iters,', for', chrom, start, end)\n",
    "        print(len(flat_seqs))\n",
    "        \n",
    "        seq_1hot_batch = []\n",
    "        for i in range(batch_size):\n",
    "            seq_1hot_mut = permute_seq_k(seq_1hot,k= shuffle_k)\n",
    "            s = scan_motif(seq_1hot_mut, motif  )\n",
    "            for i in np.where(s > ctcf_thresh)[0]:\n",
    "                #seq_1hot_mut[i-motif_window:i+motif_window] = permute_seq_k(seq_1hot_mut[i-motif_window:i+motif_window], k=2)\n",
    "                seq_1hot_mut[i-motif_window+1:i+motif_window] = seq_1hot_mut[i-motif_window+1:i+motif_window][mot_shuf]\n",
    "            seq_1hot_batch.append(seq_1hot_mut)\n",
    "        seq_1hot_batch = np.array(seq_1hot_batch)\n",
    "\n",
    "        pred = seqnn_model.predict(seq_1hot_batch, batch_size=batch_size)\n",
    "        scores = np.sum( pred**2, axis=-1).sum(axis=-1)\n",
    "        scores_pixelwise = np.max(pred**2, axis=-1).max(axis=-1)\n",
    "\n",
    "        if np.any( (np.min(scores) < scores_thresh) * (np.min(scores_pixelwise) < scores_pixelwise_thresh)):\n",
    "            best_ind = np.argmin(scores_pixelwise)\n",
    "            best_seq = seq_1hot_batch[best_ind]\n",
    "            best_pred = pred[best_ind]\n",
    "            best_score, best_score_pixelwise = scores[best_ind] , scores_pixelwise[best_ind]\n",
    "            num_iters = max_iters\n",
    "            print('success: best seq, thresh', np.min(scores),' pixelwise',np.min(scores_pixelwise))\n",
    "\n",
    "        else: \n",
    "            best_ind = np.argmin(scores_pixelwise)\n",
    "            best_seq = seq_1hot_batch[best_ind]\n",
    "            best_pred = pred[best_ind]\n",
    "            best_score, best_score_pixelwise = scores[best_ind] , scores_pixelwise[best_ind]\n",
    "            print('trying: best seq, thresh', np.min(scores),' pixelwise',np.min(scores_pixelwise))\n",
    "\n",
    "        num_iters +=1\n",
    "        if num_iters >= max_iters:\n",
    "            print('max iters exceeded')\n",
    "            flat_seqs.append( [best_seq, best_pred, best_score, best_score_pixelwise] )\n",
    "            #raise ValueError('cannot generate flat sequence for', chrom, start, end)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9e7da-ab1b-453f-bf73-12848957e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('backround_seqs.fa','w') as f:\n",
    "    for i in range(len(flat_seqs)):\n",
    "        f.write('>seq'+str(i)+'_score'+str(int(flat_seqs[i][2]))+'_pixelwise'+str(int(flat_seqs[i][3]*1000))+'\\n')\n",
    "        f.write(dna_io.hot1_dna(flat_seqs[i][0])+'\\n')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748b91d-7213-44a5-905e-5fd11c1494b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))#,6))\n",
    "\n",
    "target_ind = 0\n",
    "vlim = 1.5\n",
    "\n",
    "for i in range(len(flat_seqs)):\n",
    "    flat_pred = flat_seqs[i][1]\n",
    "    \n",
    "    plt.subplot(3,4, i+1)\n",
    "    im = plt.matshow(\n",
    "            from_upper_triu(  flat_pred[:,target_ind], target_map_size,hic_diags),\n",
    "             vmin=-1*vlim,vmax=vlim, fignum=False,cmap='RdBu_r')\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.title('tot '+\n",
    "            str(np.round(flat_seqs[i][2],0).astype(int))+'\\n pixel '+\n",
    "            str(np.round(flat_seqs[i][3],4)) ) \n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d9cfec-cc89-43c6-985c-ba4151c638d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_panels = batch_size\n",
    "#plt.figure(figsize=(5*2,2*num_panels))\n",
    "plt.figure(figsize=(8,8))#,6))\n",
    "\n",
    "target_ind = 0\n",
    "vlim = 1.5\n",
    "\n",
    "for i in range(len(flat_seqs)):\n",
    "    flat_pred = flat_seqs[i][1]\n",
    "    \n",
    "    plt.subplot(3,4, i+1)\n",
    "    im = plt.matshow(\n",
    "            from_upper_triu(  flat_pred[:,target_ind], target_map_size,hic_diags),\n",
    "             vmin=-1*vlim,vmax=vlim, fignum=False,cmap='RdBu_r')\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.title('tot '+\n",
    "            str(np.round(flat_seqs[i][2],0).astype(int))+'\\n pixel '+\n",
    "            str(np.round(flat_seqs[i][3],4)) ) \n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basenji-geoff",
   "language": "python",
   "name": "basenji-geoff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
