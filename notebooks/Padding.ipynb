{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85365f8-cb44-4231-af93-c2a3762c0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import bioframe \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import json\n",
    "from io import StringIO\n",
    "import random\n",
    "\n",
    "import pysam\n",
    "import h5py\n",
    "\n",
    "from Bio import motifs\n",
    "from Bio import pairwise2\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef774f8-dc36-4ddd-bb0a-e921f088e8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 10:06:39.714455: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /spack/apps/linux-centos7-x86_64/gcc-8.3.0/python-3.9.2-uvcroioc4witkp6qf7mbebof5ix4wlb6/lib:/spack/apps/linux-centos7-x86_64/gcc-8.3.0/pmix-3.1.3-3sm6emyqaxapunh7rwbjvtaqoqe2e5z3/lib:/spack/apps/linux-centos7-x86_64/gcc-8.3.0/openmpi-4.0.2-ipm3dnvlbtxawpi4ifz7jma6jgr7mexq/lib:/spack/apps/linux-centos7-x86_64/gcc-8.3.0/openblas-0.3.8-2no6mfziiclwxb7lstxoos335gnhjpes/lib:/spack/apps/gcc/8.3.0/lib64::/home1/smaruj/software/GSL/lib:/home1/smaruj/software/HTSLIB/lib\n",
      "2022-07-12 10:06:39.714490: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/home1/smaruj/akita_utils/\")\n",
    "\n",
    "# from akita_utils import *\n",
    "import akita_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1b8424-5a6d-4817-be16-899ae47ead16",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_open = pysam.Fastafile(\"/project/fudenber_735/genomes/mm10/mm10.fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c8f09c-dcce-4b5a-9166-7b7089915c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow:  2.9.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow: \", tf.__version__)\n",
    "\n",
    "from basenji import dataset, seqnn, dna_io, stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f0c251-ba4b-4968-b0c7-273ccf8b483f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 10:06:42.149619: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /spack/apps/linux-centos7-x86_64/gcc-8.3.0/python-3.9.2-uvcroioc4witkp6qf7mbebof5ix4wlb6/lib:/spack/apps/linux-centos7-x86_64/gcc-8.3.0/pmix-3.1.3-3sm6emyqaxapunh7rwbjvtaqoqe2e5z3/lib:/spack/apps/linux-centos7-x86_64/gcc-8.3.0/openmpi-4.0.2-ipm3dnvlbtxawpi4ifz7jma6jgr7mexq/lib:/spack/apps/linux-centos7-x86_64/gcc-8.3.0/openblas-0.3.8-2no6mfziiclwxb7lstxoos335gnhjpes/lib:/spack/apps/gcc/8.3.0/lib64::/home1/smaruj/software/GSL/lib:/home1/smaruj/software/HTSLIB/lib\n",
      "2022-07-12 10:06:42.149662: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-12 10:06:42.149706: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (d11-05.hpc.usc.edu): /proc/driver/nvidia/version does not exist\n",
      "2022-07-12 10:06:42.150029: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1310720, 4)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1310720, 4)  0          ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)  , ())                                                             \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1310720, 4)  0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 1310720, 4)   0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1310720, 128  7680        ['re_lu[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1310720, 128  512        ['conv1d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 655360, 128)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 655360, 128)  0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 655360, 128)  81920       ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 655360, 128)  512        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 327680, 128)  0          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 327680, 128)  0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 327680, 128)  81920       ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 327680, 128)  512        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 163840, 128)  0          ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 163840, 128)  0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 163840, 128)  81920       ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 163840, 128)  512        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 81920, 128)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 81920, 128)   0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 81920, 128)   81920       ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 81920, 128)  512         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 40960, 128)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 40960, 128)   0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 40960, 128)   81920       ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 40960, 128)  512         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 20480, 128)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 20480, 128)   0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 20480, 128)   81920       ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 20480, 128)  512         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 10240, 128)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 10240, 128)   0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 10240, 128)   81920       ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 10240, 128)  512         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 5120, 128)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 5120, 128)    0           ['max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 5120, 128)    81920       ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 5120, 128)   512         ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 2560, 128)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 2560, 128)    0           ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 2560, 128)    81920       ['re_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 2560, 128)   512         ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_9 (MaxPooling1D)  (None, 1280, 128)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 1280, 128)    0           ['max_pooling1d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 1280, 128)    81920       ['re_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 1280, 128)   512         ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_10 (MaxPooling1D  (None, 640, 128)    0           ['batch_normalization_10[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 640, 128)     0           ['max_pooling1d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 640, 64)      24576       ['re_lu_11[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 640, 64)     256         ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 640, 64)      0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 640, 128)     8192        ['re_lu_12[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 640, 128)    512         ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 640, 128)     0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 640, 128)     0           ['max_pooling1d_10[0][0]',       \n",
      "                                                                  'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 640, 128)     0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 640, 64)      24576       ['re_lu_13[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 640, 64)     256         ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, 640, 64)      0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 640, 128)     8192        ['re_lu_14[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 640, 128)    512         ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 640, 128)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 640, 128)     0           ['add[0][0]',                    \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, 640, 128)     0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 640, 64)      24576       ['re_lu_15[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 640, 64)     256         ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)                (None, 640, 64)      0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 640, 128)     8192        ['re_lu_16[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 640, 128)    512         ['conv1d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 640, 128)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 640, 128)     0           ['add_1[0][0]',                  \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)                (None, 640, 128)     0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 640, 64)      24576       ['re_lu_17[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 640, 64)     256         ['conv1d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)                (None, 640, 64)      0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 640, 128)     8192        ['re_lu_18[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 640, 128)    512         ['conv1d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 640, 128)     0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 640, 128)     0           ['add_2[0][0]',                  \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)                (None, 640, 128)     0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 640, 64)      24576       ['re_lu_19[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 640, 64)     256         ['conv1d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, 640, 64)      0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 640, 128)     8192        ['re_lu_20[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 640, 128)    512         ['conv1d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 640, 128)     0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 640, 128)     0           ['add_3[0][0]',                  \n",
      "                                                                  'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)                (None, 640, 128)     0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 640, 64)      24576       ['re_lu_21[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 640, 64)     256         ['conv1d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)                (None, 640, 64)      0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 640, 128)     8192        ['re_lu_22[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 640, 128)    512         ['conv1d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 640, 128)     0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 640, 128)     0           ['add_4[0][0]',                  \n",
      "                                                                  'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)                (None, 640, 128)     0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 640, 64)      24576       ['re_lu_23[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 640, 64)     256         ['conv1d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 640, 64)      0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 640, 128)     8192        ['re_lu_24[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 640, 128)    512         ['conv1d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 640, 128)     0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 640, 128)     0           ['add_5[0][0]',                  \n",
      "                                                                  'dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 640, 128)     0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 640, 64)      24576       ['re_lu_25[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 640, 64)     256         ['conv1d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 640, 64)      0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 640, 128)     8192        ['re_lu_26[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 640, 128)    512         ['conv1d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 640, 128)     0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 640, 128)     0           ['add_6[0][0]',                  \n",
      "                                                                  'dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 640, 128)     0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 640, 64)      24576       ['re_lu_27[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 640, 64)     256         ['conv1d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 640, 64)      0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 640, 128)     8192        ['re_lu_28[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 640, 128)    512         ['conv1d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 640, 128)     0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 640, 128)     0           ['add_7[0][0]',                  \n",
      "                                                                  'dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 640, 128)     0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 640, 64)      24576       ['re_lu_29[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 640, 64)     256         ['conv1d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)                (None, 640, 64)      0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 640, 128)     8192        ['re_lu_30[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 640, 128)    512         ['conv1d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 640, 128)     0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 640, 128)     0           ['add_8[0][0]',                  \n",
      "                                                                  'dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)                (None, 640, 128)     0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 640, 64)      24576       ['re_lu_31[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 640, 64)     256         ['conv1d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)                (None, 640, 64)      0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 640, 128)     8192        ['re_lu_32[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 640, 128)    512         ['conv1d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 640, 128)     0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 640, 128)     0           ['add_9[0][0]',                  \n",
      "                                                                  'dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)                (None, 640, 128)     0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 640, 80)      51200       ['re_lu_33[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 640, 80)     320         ['conv1d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)                (None, 640, 80)      0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " one_to_two (OneToTwo)          (None, 640, 640, 80  0           ['re_lu_34[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)                (None, 640, 640, 80  0           ['one_to_two[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 640, 640, 80  57600       ['re_lu_35[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 640, 640, 80  320        ['conv2d[0][0]']                 \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " symmetrize2d (Symmetrize2D)    (None, 640, 640, 80  0           ['batch_normalization_34[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)                (None, 640, 640, 80  0           ['symmetrize2d[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 640, 640, 40  28800       ['re_lu_36[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 640, 640, 40  160        ['conv2d_1[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)                (None, 640, 640, 40  0           ['batch_normalization_35[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 640, 640, 80  3200        ['re_lu_37[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 640, 640, 80  320        ['conv2d_2[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 640, 640, 80  0           ['batch_normalization_36[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 640, 640, 80  0           ['symmetrize2d[0][0]',           \n",
      "                                )                                 'dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " symmetrize2d_1 (Symmetrize2D)  (None, 640, 640, 80  0           ['add_11[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 640, 640, 80  0           ['symmetrize2d_1[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 640, 640, 40  28800       ['re_lu_38[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 640, 640, 40  160        ['conv2d_3[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 640, 640, 40  0           ['batch_normalization_37[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 640, 640, 80  3200        ['re_lu_39[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 640, 640, 80  320        ['conv2d_4[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 640, 640, 80  0           ['batch_normalization_38[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 640, 640, 80  0           ['symmetrize2d_1[0][0]',         \n",
      "                                )                                 'dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " symmetrize2d_2 (Symmetrize2D)  (None, 640, 640, 80  0           ['add_12[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 640, 640, 80  0           ['symmetrize2d_2[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 640, 640, 40  28800       ['re_lu_40[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 640, 640, 40  160        ['conv2d_5[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 640, 640, 40  0           ['batch_normalization_39[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 640, 640, 80  3200        ['re_lu_41[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 640, 640, 80  320        ['conv2d_6[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 640, 640, 80  0           ['batch_normalization_40[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 640, 640, 80  0           ['symmetrize2d_2[0][0]',         \n",
      "                                )                                 'dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " symmetrize2d_3 (Symmetrize2D)  (None, 640, 640, 80  0           ['add_13[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)                (None, 640, 640, 80  0           ['symmetrize2d_3[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 640, 640, 40  28800       ['re_lu_42[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 640, 640, 40  160        ['conv2d_7[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 640, 640, 40  0           ['batch_normalization_41[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 640, 640, 80  3200        ['re_lu_43[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 640, 640, 80  320        ['conv2d_8[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 640, 640, 80  0           ['batch_normalization_42[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 640, 640, 80  0           ['symmetrize2d_3[0][0]',         \n",
      "                                )                                 'dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " symmetrize2d_4 (Symmetrize2D)  (None, 640, 640, 80  0           ['add_14[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 640, 640, 80  0           ['symmetrize2d_4[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 640, 640, 40  28800       ['re_lu_44[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 640, 640, 40  160        ['conv2d_9[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 640, 640, 40  0           ['batch_normalization_43[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 640, 640, 80  3200        ['re_lu_45[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 640, 640, 80  320        ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 640, 640, 80  0           ['batch_normalization_44[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 640, 640, 80  0           ['symmetrize2d_4[0][0]',         \n",
      "                                )                                 'dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " symmetrize2d_5 (Symmetrize2D)  (None, 640, 640, 80  0           ['add_15[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 640, 640, 80  0           ['symmetrize2d_5[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 640, 640, 40  28800       ['re_lu_46[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 640, 640, 40  160        ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 640, 640, 40  0           ['batch_normalization_45[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 640, 640, 80  3200        ['re_lu_47[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 640, 640, 80  320        ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 640, 640, 80  0           ['batch_normalization_46[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 640, 640, 80  0           ['symmetrize2d_5[0][0]',         \n",
      "                                )                                 'dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " symmetrize2d_6 (Symmetrize2D)  (None, 640, 640, 80  0           ['add_16[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " squeeze_excite (SqueezeExcite)  (None, 640, 640, 80  2010       ['symmetrize2d_6[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " cropping2d (Cropping2D)        (None, 512, 512, 80  0           ['squeeze_excite[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " upper_tri (UpperTri)           (None, 130305, 80)   0           ['cropping2d[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)                (None, 130305, 80)   0           ['upper_tri[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 130305, 5)    405         ['re_lu_48[0][0]']               \n",
      "                                                                                                  \n",
      " switch_reverse_triu (SwitchRev  (None, 130305, 5)   0           ['dense[0][0]',                  \n",
      " erseTriu)                                                        'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,508,143\n",
      "Trainable params: 1,499,183\n",
      "Non-trainable params: 8,960\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "model_strides [2048, 2048]\n",
      "target_lengths [130305, 130305]\n",
      "target_crops [-64833, -64833]\n",
      "built\n",
      "restored\n"
     ]
    }
   ],
   "source": [
    "# NOTE\n",
    "# head_i = 0 #human\n",
    "# head_i = 1 #mouse\n",
    "#\n",
    "\n",
    "head_i = 1 #mouse\n",
    "# head_i = 0\n",
    "model_num = 1 #which fold to use\n",
    "\n",
    "\n",
    "#base_dir = '/project/fudenber_735/backup/DNN_HiC/human-mouse_5-16-21/'\n",
    "#model_dir = base_dir+\"/f\"+str(model_num)+\"_c0/train/\"\n",
    "\n",
    "base_dir = \"/project/fudenber_735/tensorflow_models/akita/v2/models/\"\n",
    "model_dir = base_dir + \"/f\" + str(model_num) + \"c0/train/\"\n",
    "model_file  = model_dir + \"/model\" + str(head_i) + \"_best.h5\"\n",
    "\n",
    "\n",
    "# model_dir = '/home1/fudenber/repositories/basenji/manuscripts/akita/'\n",
    "# model_file = model_dir+'/model_best.h5'\n",
    "\n",
    "params_file = model_dir + \"/params.json\"\n",
    "# params_file -> json (dict) with model's parameters\n",
    "with open(params_file) as params_open:\n",
    "    params = json.load(params_open)\n",
    "    params_model = params[\"model\"]\n",
    "    params_train = params[\"train\"]\n",
    "seq_length = params_model[\"seq_length\"]\n",
    "params_model[\"verbose\"] = False\n",
    "\n",
    "seqnn_model = seqnn.SeqNN(params_model)\n",
    "print(\"built\")\n",
    "\n",
    "seqnn_model.restore(model_file, head_i=head_i)    # model with the mouse head\n",
    "print(\"restored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b049319-7fbd-459c-b007-7e514b28b455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hic_diags:  2\n",
      "target_crop:  64\n",
      "seq_length:  1310720\n",
      "target_length_cropped:  130305\n",
      "target_map_size:  512\n",
      "shape of triu_tup[0]:  (130305,)\n"
     ]
    }
   ],
   "source": [
    "hic_diags = params_model[\"diagonal_offset\"]\n",
    "try:\n",
    "    target_crop = params_model[\"trunk\"][-2][\"cropping\"]\n",
    "except:\n",
    "    target_crop = params_model[\"target_crop\"]\n",
    "\n",
    "print(\"hic_diags: \", hic_diags) \n",
    "print(\"target_crop: \", target_crop)\n",
    "print(\"seq_length: \", seq_length)\n",
    "\n",
    "target_length_cropped = int((seq_length//2048 - target_crop*2 - hic_diags) * ((seq_length//2048 - target_crop*2 - hic_diags) +1)/2) \n",
    "target_map_size = seq_length//2048  - target_crop*2 \n",
    "triu_tup = np.triu_indices(target_map_size, 2)    # Return the indices for the upper-triangle of an (n, m) array, here k=2 (diagonal offset)\n",
    "# target_map_size, target_length_cropped, triu_tup[0].shape\n",
    "\n",
    "print(\"target_length_cropped: \", target_length_cropped)\n",
    "print(\"target_map_size: \", target_map_size)\n",
    "print(\"shape of triu_tup[0]: \", triu_tup[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea3f70e6-940f-400a-804e-594e5919b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_file = base_dir + '../analysis/background_seqs.fa'\n",
    "background_seqs = []\n",
    "with open(background_file,'r') as f:\n",
    "  for line in f.readlines():\n",
    "    if '>' in line: continue\n",
    "    background_seqs.append(dna_io.dna_1hot(line.strip())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56c78156-e742-4998-8ae2-4bce2de57a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(background_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35658d34-3afd-4335-91a4-f5092d24d0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 duplicates removed for  /project/fudenber_735/tensorflow_models/akita/v2/analysis/permute_boundaries_motifs_ctcf_mm10_model7/scd.h5\n",
      "29 duplicates removed for  /project/fudenber_735/tensorflow_models/akita/v2/analysis/permute_boundaries_motifs_ctcf_mm10_model1/scd.h5\n",
      "annotating each site with boundary-wide scores\n",
      "filtering sites by overlap with rmsk\n",
      "df prepared\n"
     ]
    }
   ],
   "source": [
    "seq_coords_df = akita_utils.prepare_insertion_tsv(\n",
    "    h5_dirs = '/project/fudenber_735/tensorflow_models/akita/v2/analysis/permute_boundaries_motifs_ctcf_mm10_model*/scd.h5',\n",
    "    score_key = 'SCD',\n",
    "    pad_flank = 0, #how much flanking sequence around the sites to include\n",
    "    weak_thresh_pct = 1, # don't use sites weaker than this, might be artifacts\n",
    "    weak_num = 20 ,\n",
    "    strong_thresh_pct = 99, # don't use sites weaker than this, might be artifacts\n",
    "    strong_num = 20 ,\n",
    "    save_tsv=None, # optional filename to save a tsv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c2e0a9d-6343-4cff-8bb3-68eccde7f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf4fad4c-b7c6-40e6-b54b-3a096e521946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_inserts = 2\n",
    "# one_side_radius = 100 \n",
    "# spacer = one_side_radius - padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "911946cd-9cec-4f4e-af90-c65df1f60a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# motif_len = 19\n",
    "# multi_insert_length = num_inserts * (motif_len + 2 * one_side_radius)\n",
    "# print(multi_insert_length//num_inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88862a2f-18dd-4792-a8a6-21aeea8abffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def multiple_padding(seq_coords_df, \n",
    "                     background_seqs, \n",
    "                     pad_list,\n",
    "                     orientation=\"same\",\n",
    "                     plotting=True, \n",
    "                     num_inserts=2, \n",
    "                     one_side_radius=100, \n",
    "                     motif_len=19):\n",
    "    \n",
    "    orientation_types = [\"same\", \"convergent\", \"divergent\"]\n",
    "    if orientation not in orientation_types:\n",
    "        raise ValueError(\"Invalid orientation. Expected one of: %s\" % orientation_types)\n",
    "    \n",
    "    nr_seq = len(seq_coords_df)\n",
    "    nr_bg = len(background_seqs)\n",
    "    \n",
    "    multi_insert_length = num_inserts * (motif_len + 2 * one_side_radius)\n",
    "    \n",
    "    \n",
    "    for padding in pad_list:\n",
    "        \n",
    "        print(f\"padding = {padding} || Started working on padding = {padding}\")\n",
    "        \n",
    "        spacer = one_side_radius - padding\n",
    "        \n",
    "        offsets = []\n",
    "\n",
    "        for i in range(num_inserts):\n",
    "            offsets.append( seq_length//2 - multi_insert_length//2 + i * (multi_insert_length//2) + spacer)\n",
    "\n",
    "        all_inserts = []\n",
    "\n",
    "        # inserting only to the first background sequence\n",
    "        \n",
    "        if orientation == \"same\":\n",
    "            for background_seq in background_seqs:\n",
    "                for i in seq_coords_df.index:\n",
    "                    seq_1hot = background_seq.copy()\n",
    "                    this_row = seq_coords_df.iloc[i]\n",
    "                    seq_1hot_CTCF_pad = dna_io.dna_1hot(genome_open.fetch(this_row.chrom, this_row.start-padding, this_row.end+padding).upper())\n",
    "                    if this_row.strand == '-': \n",
    "                        seq_1hot_CTCF_pad = dna_io.hot1_rc(seq_1hot_CTCF_pad)\n",
    "                    # print(this_row.strand, Seq(genome_open.fetch(this_row.chrom, this_row.start-padding, this_row.end+padding).upper()))\n",
    "                    for offset in offsets:\n",
    "                        seq_1hot[offset : offset + len(seq_1hot_CTCF_pad)] = seq_1hot_CTCF_pad\n",
    "                    all_inserts.append(seq_1hot)\n",
    "                    # print(seq_1hot[655241:655241+19] == seq_1hot[655260:655260+19])\n",
    "            all_inserts = np.array(all_inserts)\n",
    "        \n",
    "        elif orientation == \"convergent\":\n",
    "            for background_seq in background_seqs:\n",
    "                for i in seq_coords_df.index:\n",
    "                    seq_1hot = background_seq.copy()\n",
    "                    this_row = seq_coords_df.iloc[i]\n",
    "                    seq_1hot_CTCF_pad_left = dna_io.dna_1hot(genome_open.fetch(this_row.chrom, this_row.start-padding, this_row.end+padding).upper())\n",
    "                    if this_row.strand == '-': \n",
    "                        seq_1hot_CTCF_pad_left = dna_io.hot1_rc(seq_1hot_CTCF_pad_left)\n",
    "                    # print(this_row.strand, Seq(genome_open.fetch(this_row.chrom, this_row.start-padding, this_row.end+padding).upper()))\n",
    "                    seq_1hot_CTCF_pad_right = dna_io.hot1_rc(seq_1hot_CTCF_pad_left)\n",
    "                    for o in range(len(offsets)):\n",
    "                        if o % 2 == 0:\n",
    "                            seq_1hot[offsets[o] : offsets[o] + len(seq_1hot_CTCF_pad_left)] = seq_1hot_CTCF_pad_left\n",
    "                        else:\n",
    "                            seq_1hot[offsets[o] : offsets[o] + len(seq_1hot_CTCF_pad_right)] = seq_1hot_CTCF_pad_right\n",
    "                    all_inserts.append(seq_1hot)\n",
    "                    # print(seq_1hot[655241:655241+19] == seq_1hot[655260:655260+19])\n",
    "            all_inserts = np.array(all_inserts) \n",
    "        \n",
    "        elif orientation == \"divergent\":\n",
    "            for background_seq in background_seqs:\n",
    "                for i in seq_coords_df.index:\n",
    "                    seq_1hot = background_seq.copy()\n",
    "                    this_row = seq_coords_df.iloc[i]\n",
    "                    seq_1hot_CTCF_pad_left = dna_io.dna_1hot(genome_open.fetch(this_row.chrom, this_row.start-padding, this_row.end+padding).upper())\n",
    "                    if this_row.strand == '-': \n",
    "                        seq_1hot_CTCF_pad_left = dna_io.hot1_rc(seq_1hot_CTCF_pad_left)\n",
    "                    # print(this_row.strand, Seq(genome_open.fetch(this_row.chrom, this_row.start-padding, this_row.end+padding).upper()))\n",
    "                    seq_1hot_CTCF_pad_right = dna_io.hot1_rc(seq_1hot_CTCF_pad_left)\n",
    "                    for o in range(len(offsets)):\n",
    "                        if o % 2 == 0:\n",
    "                            seq_1hot[offsets[o] : offsets[o] + len(seq_1hot_CTCF_pad_left)] = seq_1hot_CTCF_pad_left\n",
    "                        else:\n",
    "                            seq_1hot[offsets[o] : offsets[o] + len(seq_1hot_CTCF_pad_right)] = seq_1hot_CTCF_pad_right\n",
    "                    all_inserts.append(seq_1hot)\n",
    "                    # print(seq_1hot[655241:655241+19] == seq_1hot[655260:655260+19])\n",
    "            all_inserts = np.array(all_inserts) \n",
    "        \n",
    "        print(f\"padding = {padding} || Prediction\")\n",
    "        pred = seqnn_model.predict(all_inserts, batch_size=10)\n",
    "\n",
    "        scd_score = []\n",
    "\n",
    "        # plt.figure(figsize=(8*3,5*3))\n",
    "        \n",
    "#         if plotting == True:\n",
    "            \n",
    "#             plt.figure(figsize=(8*3,5*3))\n",
    "            \n",
    "#             print(f\"padding = {padding} || Plotting\")\n",
    "            \n",
    "#             target_ind = 0\n",
    "#             vlim = .5\n",
    "#             bin_mid = target_map_size//2\n",
    "#             window = 50\n",
    "#             for i in range(40):\n",
    "#                 insert_pred = pred[i]\n",
    "\n",
    "#                 plt.subplot(8,5, i+1)\n",
    "#                 im = plt.matshow(\n",
    "#                         akita_utils.from_upper_triu(  \n",
    "#                         insert_pred[:,target_ind], target_map_size,hic_diags),\n",
    "#                         vmin=-1*vlim, vmax=vlim, fignum=False,cmap='RdBu_r')\n",
    "#                 plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "#                 plt.title('insert-scd: '+str(  np.sqrt( (insert_pred**2).sum(axis=0)  ).mean() ) \n",
    "#                           ) \n",
    "#                 #plt.axis([ bin_mid  - window,bin_mid+window,bin_mid-window, bin_mid+window])\n",
    "#             plt.tight_layout()\n",
    "#             # plt.savefig(f\"Padding_{padding}_{orientation}.png\")\n",
    "#             plt.show()\n",
    "        \n",
    "        print(f\"padding = {padding} || SCD Calculation\")\n",
    "        for i in range(nr_seq * nr_bg):\n",
    "            insert_pred = pred[i]\n",
    "            # print(i, np.sqrt( (insert_pred**2).sum(axis=0)))\n",
    "            scd_score.append(np.sqrt( (insert_pred**2).sum(axis=0)  ).mean())\n",
    "        \n",
    "        np_scd_score = np.array(scd_score)\n",
    "        reshaped_scd_score = np_scd_score.reshape((nr_bg, nr_seq))\n",
    "        # seq_coords_df[f\"Pad_{padding}_SCD\"] = scd_score\n",
    "        \n",
    "        for bs in range(len(background_seqs)):\n",
    "            seq_coords_df[f\"Pad_{padding}_b{bs}_SCD\"] = reshaped_scd_score[bs, :]\n",
    "        \n",
    "    return seq_coords_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7a0fa42-0509-48ae-84c3-7c7e50a262d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_list = [k for k in range(50, 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7812721d-2d53-4420-85bb-f688d0fc6a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding = 50 || Started working on padding = 50\n",
      "padding = 50 || Prediction\n",
      "40/40 [==============================] - 452s 11s/step\n",
      "padding = 50 || SCD Calculation\n",
      "padding = 51 || Started working on padding = 51\n",
      "padding = 51 || Prediction\n",
      "40/40 [==============================] - 450s 11s/step\n",
      "padding = 51 || SCD Calculation\n",
      "padding = 52 || Started working on padding = 52\n",
      "padding = 52 || Prediction\n",
      "40/40 [==============================] - 449s 11s/step\n",
      "padding = 52 || SCD Calculation\n",
      "padding = 53 || Started working on padding = 53\n",
      "padding = 53 || Prediction\n",
      "40/40 [==============================] - 450s 11s/step\n",
      "padding = 53 || SCD Calculation\n",
      "padding = 54 || Started working on padding = 54\n",
      "padding = 54 || Prediction\n",
      "40/40 [==============================] - 449s 11s/step\n",
      "padding = 54 || SCD Calculation\n",
      "padding = 55 || Started working on padding = 55\n",
      "padding = 55 || Prediction\n",
      "40/40 [==============================] - 449s 11s/step\n",
      "padding = 55 || SCD Calculation\n",
      "padding = 56 || Started working on padding = 56\n",
      "padding = 56 || Prediction\n",
      "40/40 [==============================] - 448s 11s/step\n",
      "padding = 56 || SCD Calculation\n",
      "padding = 57 || Started working on padding = 57\n",
      "padding = 57 || Prediction\n",
      "40/40 [==============================] - 449s 11s/step\n",
      "padding = 57 || SCD Calculation\n",
      "padding = 58 || Started working on padding = 58\n",
      "padding = 58 || Prediction\n",
      "40/40 [==============================] - 449s 11s/step\n",
      "padding = 58 || SCD Calculation\n",
      "padding = 59 || Started working on padding = 59\n",
      "padding = 59 || Prediction\n",
      "40/40 [==============================] - 449s 11s/step\n",
      "padding = 59 || SCD Calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_6752212/ipykernel_207953/2672018541.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  seq_coords_df[f\"Pad_{padding}_b{bs}_SCD\"] = reshaped_scd_score[bs, :]\n",
      "/tmp/SLURM_6752212/ipykernel_207953/2672018541.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  seq_coords_df[f\"Pad_{padding}_b{bs}_SCD\"] = reshaped_scd_score[bs, :]\n",
      "/tmp/SLURM_6752212/ipykernel_207953/2672018541.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  seq_coords_df[f\"Pad_{padding}_b{bs}_SCD\"] = reshaped_scd_score[bs, :]\n",
      "/tmp/SLURM_6752212/ipykernel_207953/2672018541.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  seq_coords_df[f\"Pad_{padding}_b{bs}_SCD\"] = reshaped_scd_score[bs, :]\n",
      "/tmp/SLURM_6752212/ipykernel_207953/2672018541.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  seq_coords_df[f\"Pad_{padding}_b{bs}_SCD\"] = reshaped_scd_score[bs, :]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>strand</th>\n",
       "      <th>genomic_SCD</th>\n",
       "      <th>Pad_50_b0_SCD</th>\n",
       "      <th>Pad_50_b1_SCD</th>\n",
       "      <th>Pad_50_b2_SCD</th>\n",
       "      <th>Pad_50_b3_SCD</th>\n",
       "      <th>...</th>\n",
       "      <th>Pad_59_b0_SCD</th>\n",
       "      <th>Pad_59_b1_SCD</th>\n",
       "      <th>Pad_59_b2_SCD</th>\n",
       "      <th>Pad_59_b3_SCD</th>\n",
       "      <th>Pad_59_b4_SCD</th>\n",
       "      <th>Pad_59_b5_SCD</th>\n",
       "      <th>Pad_59_b6_SCD</th>\n",
       "      <th>Pad_59_b7_SCD</th>\n",
       "      <th>Pad_59_b8_SCD</th>\n",
       "      <th>Pad_59_b9_SCD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>chr12</td>\n",
       "      <td>35192359</td>\n",
       "      <td>35192378</td>\n",
       "      <td>-</td>\n",
       "      <td>53.656250</td>\n",
       "      <td>35.093750</td>\n",
       "      <td>34.843750</td>\n",
       "      <td>32.875000</td>\n",
       "      <td>35.093750</td>\n",
       "      <td>...</td>\n",
       "      <td>35.531250</td>\n",
       "      <td>34.843750</td>\n",
       "      <td>32.812500</td>\n",
       "      <td>35.093750</td>\n",
       "      <td>40.562500</td>\n",
       "      <td>43.125000</td>\n",
       "      <td>34.875000</td>\n",
       "      <td>46.812500</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>34.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>chr8</td>\n",
       "      <td>102781112</td>\n",
       "      <td>102781131</td>\n",
       "      <td>-</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>27.156250</td>\n",
       "      <td>27.765625</td>\n",
       "      <td>29.578125</td>\n",
       "      <td>...</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>27.781250</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>30.453125</td>\n",
       "      <td>32.062500</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>29.453125</td>\n",
       "      <td>38.218750</td>\n",
       "      <td>32.312500</td>\n",
       "      <td>28.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>chr5</td>\n",
       "      <td>49961991</td>\n",
       "      <td>49962010</td>\n",
       "      <td>-</td>\n",
       "      <td>53.312500</td>\n",
       "      <td>30.656250</td>\n",
       "      <td>28.390625</td>\n",
       "      <td>28.968750</td>\n",
       "      <td>32.781250</td>\n",
       "      <td>...</td>\n",
       "      <td>31.953125</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.125000</td>\n",
       "      <td>31.234375</td>\n",
       "      <td>33.125000</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>30.734375</td>\n",
       "      <td>39.343750</td>\n",
       "      <td>33.187500</td>\n",
       "      <td>28.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>chr9</td>\n",
       "      <td>26776356</td>\n",
       "      <td>26776375</td>\n",
       "      <td>-</td>\n",
       "      <td>53.125000</td>\n",
       "      <td>30.140625</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>29.093750</td>\n",
       "      <td>33.218750</td>\n",
       "      <td>...</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>30.343750</td>\n",
       "      <td>29.546875</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>35.031250</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>30.843750</td>\n",
       "      <td>41.968750</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>29.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>chr9</td>\n",
       "      <td>51152589</td>\n",
       "      <td>51152608</td>\n",
       "      <td>-</td>\n",
       "      <td>53.062500</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>26.437500</td>\n",
       "      <td>26.937500</td>\n",
       "      <td>28.953125</td>\n",
       "      <td>...</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>26.609375</td>\n",
       "      <td>28.234375</td>\n",
       "      <td>29.296875</td>\n",
       "      <td>30.765625</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>28.906250</td>\n",
       "      <td>37.187500</td>\n",
       "      <td>27.921875</td>\n",
       "      <td>28.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>chr8</td>\n",
       "      <td>58566264</td>\n",
       "      <td>58566283</td>\n",
       "      <td>+</td>\n",
       "      <td>52.875000</td>\n",
       "      <td>23.968750</td>\n",
       "      <td>25.921875</td>\n",
       "      <td>22.187500</td>\n",
       "      <td>27.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.531250</td>\n",
       "      <td>26.203125</td>\n",
       "      <td>24.875000</td>\n",
       "      <td>27.781250</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>33.906250</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>25.812500</td>\n",
       "      <td>26.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>chr12</td>\n",
       "      <td>40837731</td>\n",
       "      <td>40837750</td>\n",
       "      <td>+</td>\n",
       "      <td>52.843750</td>\n",
       "      <td>28.953125</td>\n",
       "      <td>27.062500</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.078125</td>\n",
       "      <td>28.125000</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>33.062500</td>\n",
       "      <td>30.843750</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>30.296875</td>\n",
       "      <td>41.468750</td>\n",
       "      <td>32.656250</td>\n",
       "      <td>28.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>chr8</td>\n",
       "      <td>36523116</td>\n",
       "      <td>36523135</td>\n",
       "      <td>-</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>26.484375</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>30.562500</td>\n",
       "      <td>...</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>26.671875</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>30.609375</td>\n",
       "      <td>30.671875</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>38.562500</td>\n",
       "      <td>31.718750</td>\n",
       "      <td>28.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>chr6</td>\n",
       "      <td>101261721</td>\n",
       "      <td>101261740</td>\n",
       "      <td>-</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>28.078125</td>\n",
       "      <td>27.843750</td>\n",
       "      <td>30.218750</td>\n",
       "      <td>...</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>28.656250</td>\n",
       "      <td>28.890625</td>\n",
       "      <td>30.125000</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>29.187500</td>\n",
       "      <td>37.812500</td>\n",
       "      <td>31.296875</td>\n",
       "      <td>28.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>chr11</td>\n",
       "      <td>57467954</td>\n",
       "      <td>57467973</td>\n",
       "      <td>-</td>\n",
       "      <td>52.375000</td>\n",
       "      <td>30.406250</td>\n",
       "      <td>29.937500</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.687500</td>\n",
       "      <td>...</td>\n",
       "      <td>30.578125</td>\n",
       "      <td>30.437500</td>\n",
       "      <td>30.546875</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>35.218750</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>32.218750</td>\n",
       "      <td>43.937500</td>\n",
       "      <td>33.781250</td>\n",
       "      <td>30.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>chr4</td>\n",
       "      <td>70621534</td>\n",
       "      <td>70621553</td>\n",
       "      <td>-</td>\n",
       "      <td>52.281250</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>26.578125</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>32.531250</td>\n",
       "      <td>...</td>\n",
       "      <td>28.906250</td>\n",
       "      <td>26.812500</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>32.062500</td>\n",
       "      <td>30.687500</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>30.109375</td>\n",
       "      <td>40.937500</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>28.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>chr2</td>\n",
       "      <td>101905952</td>\n",
       "      <td>101905971</td>\n",
       "      <td>+</td>\n",
       "      <td>52.250000</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>27.234375</td>\n",
       "      <td>27.953125</td>\n",
       "      <td>28.984375</td>\n",
       "      <td>...</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>27.218750</td>\n",
       "      <td>28.515625</td>\n",
       "      <td>29.281250</td>\n",
       "      <td>31.390625</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>36.562500</td>\n",
       "      <td>27.453125</td>\n",
       "      <td>28.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>chr16</td>\n",
       "      <td>13117402</td>\n",
       "      <td>13117421</td>\n",
       "      <td>+</td>\n",
       "      <td>51.937500</td>\n",
       "      <td>29.062500</td>\n",
       "      <td>26.750000</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>31.312500</td>\n",
       "      <td>...</td>\n",
       "      <td>29.156250</td>\n",
       "      <td>26.859375</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>32.062500</td>\n",
       "      <td>31.093750</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>30.078125</td>\n",
       "      <td>40.312500</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>28.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>chr13</td>\n",
       "      <td>19698902</td>\n",
       "      <td>19698921</td>\n",
       "      <td>+</td>\n",
       "      <td>51.937500</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>30.281250</td>\n",
       "      <td>...</td>\n",
       "      <td>28.890625</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>28.328125</td>\n",
       "      <td>30.234375</td>\n",
       "      <td>34.218750</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>29.859375</td>\n",
       "      <td>37.562500</td>\n",
       "      <td>29.093750</td>\n",
       "      <td>28.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>chr9</td>\n",
       "      <td>63136044</td>\n",
       "      <td>63136063</td>\n",
       "      <td>+</td>\n",
       "      <td>51.750000</td>\n",
       "      <td>23.281250</td>\n",
       "      <td>20.578125</td>\n",
       "      <td>21.515625</td>\n",
       "      <td>26.234375</td>\n",
       "      <td>...</td>\n",
       "      <td>23.718750</td>\n",
       "      <td>23.078125</td>\n",
       "      <td>21.546875</td>\n",
       "      <td>26.265625</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>32.562500</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>33.281250</td>\n",
       "      <td>25.484375</td>\n",
       "      <td>23.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>chr12</td>\n",
       "      <td>92303369</td>\n",
       "      <td>92303388</td>\n",
       "      <td>+</td>\n",
       "      <td>51.625000</td>\n",
       "      <td>30.781250</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>32.843750</td>\n",
       "      <td>...</td>\n",
       "      <td>29.093750</td>\n",
       "      <td>27.703125</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>31.062500</td>\n",
       "      <td>30.671875</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>30.531250</td>\n",
       "      <td>38.375000</td>\n",
       "      <td>32.312500</td>\n",
       "      <td>28.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>chr11</td>\n",
       "      <td>31949597</td>\n",
       "      <td>31949616</td>\n",
       "      <td>-</td>\n",
       "      <td>51.562500</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>26.296875</td>\n",
       "      <td>26.984375</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>28.093750</td>\n",
       "      <td>27.281250</td>\n",
       "      <td>28.953125</td>\n",
       "      <td>31.671875</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>37.156250</td>\n",
       "      <td>26.546875</td>\n",
       "      <td>28.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>chr9</td>\n",
       "      <td>49494116</td>\n",
       "      <td>49494135</td>\n",
       "      <td>+</td>\n",
       "      <td>51.187500</td>\n",
       "      <td>33.468750</td>\n",
       "      <td>31.703125</td>\n",
       "      <td>31.437500</td>\n",
       "      <td>33.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>32.656250</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>33.875000</td>\n",
       "      <td>37.781250</td>\n",
       "      <td>37.281250</td>\n",
       "      <td>34.843750</td>\n",
       "      <td>44.125000</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>30.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>chr12</td>\n",
       "      <td>17554295</td>\n",
       "      <td>17554314</td>\n",
       "      <td>+</td>\n",
       "      <td>51.187500</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>24.375000</td>\n",
       "      <td>24.203125</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>25.890625</td>\n",
       "      <td>25.843750</td>\n",
       "      <td>28.906250</td>\n",
       "      <td>31.187500</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>28.890625</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>26.218750</td>\n",
       "      <td>28.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>chr9</td>\n",
       "      <td>88222169</td>\n",
       "      <td>88222188</td>\n",
       "      <td>-</td>\n",
       "      <td>51.156250</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>28.687500</td>\n",
       "      <td>26.656250</td>\n",
       "      <td>30.156250</td>\n",
       "      <td>...</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>27.687500</td>\n",
       "      <td>30.437500</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>29.718750</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>29.281250</td>\n",
       "      <td>28.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>chr7</td>\n",
       "      <td>139598311</td>\n",
       "      <td>139598330</td>\n",
       "      <td>+</td>\n",
       "      <td>0.058136</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.882812</td>\n",
       "      <td>8.070312</td>\n",
       "      <td>10.328125</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.882812</td>\n",
       "      <td>8.054688</td>\n",
       "      <td>10.320312</td>\n",
       "      <td>9.281250</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.078125</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>9.281250</td>\n",
       "      <td>9.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>chr8</td>\n",
       "      <td>45342919</td>\n",
       "      <td>45342938</td>\n",
       "      <td>+</td>\n",
       "      <td>0.058319</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.906250</td>\n",
       "      <td>8.023438</td>\n",
       "      <td>10.257812</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.898438</td>\n",
       "      <td>8.007812</td>\n",
       "      <td>10.257812</td>\n",
       "      <td>9.320312</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.203125</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>9.257812</td>\n",
       "      <td>9.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>chr2</td>\n",
       "      <td>27771666</td>\n",
       "      <td>27771685</td>\n",
       "      <td>-</td>\n",
       "      <td>0.058746</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.929688</td>\n",
       "      <td>8.015625</td>\n",
       "      <td>10.265625</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.906250</td>\n",
       "      <td>8.046875</td>\n",
       "      <td>10.296875</td>\n",
       "      <td>9.273438</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.078125</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>9.265625</td>\n",
       "      <td>9.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>chr1</td>\n",
       "      <td>35713888</td>\n",
       "      <td>35713907</td>\n",
       "      <td>+</td>\n",
       "      <td>0.059021</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.921875</td>\n",
       "      <td>8.062500</td>\n",
       "      <td>10.257812</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.898438</td>\n",
       "      <td>8.085938</td>\n",
       "      <td>10.257812</td>\n",
       "      <td>9.218750</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.242188</td>\n",
       "      <td>16.265625</td>\n",
       "      <td>9.281250</td>\n",
       "      <td>9.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>chr9</td>\n",
       "      <td>51333610</td>\n",
       "      <td>51333629</td>\n",
       "      <td>-</td>\n",
       "      <td>0.059021</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.914062</td>\n",
       "      <td>8.070312</td>\n",
       "      <td>10.265625</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.906250</td>\n",
       "      <td>8.039062</td>\n",
       "      <td>10.257812</td>\n",
       "      <td>9.203125</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.226562</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>9.296875</td>\n",
       "      <td>9.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>chr11</td>\n",
       "      <td>57783694</td>\n",
       "      <td>57783713</td>\n",
       "      <td>-</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.929688</td>\n",
       "      <td>7.953125</td>\n",
       "      <td>10.328125</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.929688</td>\n",
       "      <td>7.972656</td>\n",
       "      <td>10.296875</td>\n",
       "      <td>9.320312</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.109375</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>9.265625</td>\n",
       "      <td>9.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>chr6</td>\n",
       "      <td>94057464</td>\n",
       "      <td>94057483</td>\n",
       "      <td>+</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.898438</td>\n",
       "      <td>7.996094</td>\n",
       "      <td>10.273438</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.890625</td>\n",
       "      <td>8.015625</td>\n",
       "      <td>10.273438</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.156250</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>9.281250</td>\n",
       "      <td>9.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>chr16</td>\n",
       "      <td>23157002</td>\n",
       "      <td>23157021</td>\n",
       "      <td>-</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.906250</td>\n",
       "      <td>8.007812</td>\n",
       "      <td>10.289062</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.914062</td>\n",
       "      <td>8.007812</td>\n",
       "      <td>10.281250</td>\n",
       "      <td>9.312500</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.218750</td>\n",
       "      <td>16.265625</td>\n",
       "      <td>9.281250</td>\n",
       "      <td>9.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>chr11</td>\n",
       "      <td>102262359</td>\n",
       "      <td>102262378</td>\n",
       "      <td>-</td>\n",
       "      <td>0.061462</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.890625</td>\n",
       "      <td>7.992188</td>\n",
       "      <td>10.289062</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.890625</td>\n",
       "      <td>7.960938</td>\n",
       "      <td>10.296875</td>\n",
       "      <td>9.312500</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>10.968750</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>9.265625</td>\n",
       "      <td>9.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>chr9</td>\n",
       "      <td>71627181</td>\n",
       "      <td>71627200</td>\n",
       "      <td>+</td>\n",
       "      <td>0.062378</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.921875</td>\n",
       "      <td>8.054688</td>\n",
       "      <td>10.265625</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.906250</td>\n",
       "      <td>8.046875</td>\n",
       "      <td>10.257812</td>\n",
       "      <td>9.234375</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.203125</td>\n",
       "      <td>16.265625</td>\n",
       "      <td>9.312500</td>\n",
       "      <td>9.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>chr13</td>\n",
       "      <td>109771756</td>\n",
       "      <td>109771775</td>\n",
       "      <td>+</td>\n",
       "      <td>0.062988</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.898438</td>\n",
       "      <td>8.046875</td>\n",
       "      <td>10.281250</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.882812</td>\n",
       "      <td>8.054688</td>\n",
       "      <td>10.281250</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.242188</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>9.296875</td>\n",
       "      <td>9.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>chr11</td>\n",
       "      <td>32340269</td>\n",
       "      <td>32340288</td>\n",
       "      <td>+</td>\n",
       "      <td>0.063232</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.906250</td>\n",
       "      <td>7.976562</td>\n",
       "      <td>10.257812</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.898438</td>\n",
       "      <td>7.968750</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>9.234375</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.210938</td>\n",
       "      <td>16.296875</td>\n",
       "      <td>9.265625</td>\n",
       "      <td>9.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>chr2</td>\n",
       "      <td>107941165</td>\n",
       "      <td>107941184</td>\n",
       "      <td>-</td>\n",
       "      <td>0.063232</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.898438</td>\n",
       "      <td>8.031250</td>\n",
       "      <td>10.281250</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.906250</td>\n",
       "      <td>8.046875</td>\n",
       "      <td>10.281250</td>\n",
       "      <td>9.203125</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.312500</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>9.265625</td>\n",
       "      <td>9.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>chr7</td>\n",
       "      <td>143479908</td>\n",
       "      <td>143479927</td>\n",
       "      <td>+</td>\n",
       "      <td>0.063599</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.906250</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.273438</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.882812</td>\n",
       "      <td>7.953125</td>\n",
       "      <td>10.265625</td>\n",
       "      <td>9.289062</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>10.960938</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>9.273438</td>\n",
       "      <td>9.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>chr8</td>\n",
       "      <td>88110358</td>\n",
       "      <td>88110377</td>\n",
       "      <td>+</td>\n",
       "      <td>0.064209</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.906250</td>\n",
       "      <td>8.062500</td>\n",
       "      <td>10.281250</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.898438</td>\n",
       "      <td>8.062500</td>\n",
       "      <td>10.265625</td>\n",
       "      <td>9.296875</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.289062</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>9.265625</td>\n",
       "      <td>9.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>chr2</td>\n",
       "      <td>160592247</td>\n",
       "      <td>160592266</td>\n",
       "      <td>+</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.898438</td>\n",
       "      <td>8.039062</td>\n",
       "      <td>10.265625</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.890625</td>\n",
       "      <td>8.101562</td>\n",
       "      <td>10.273438</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.187500</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>9.343750</td>\n",
       "      <td>9.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>chr5</td>\n",
       "      <td>147936524</td>\n",
       "      <td>147936543</td>\n",
       "      <td>+</td>\n",
       "      <td>0.064636</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.882812</td>\n",
       "      <td>8.062500</td>\n",
       "      <td>10.289062</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.882812</td>\n",
       "      <td>8.054688</td>\n",
       "      <td>10.328125</td>\n",
       "      <td>9.296875</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.015625</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>9.257812</td>\n",
       "      <td>9.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>chr2</td>\n",
       "      <td>31681471</td>\n",
       "      <td>31681490</td>\n",
       "      <td>+</td>\n",
       "      <td>0.064697</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.914062</td>\n",
       "      <td>8.039062</td>\n",
       "      <td>10.265625</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.914062</td>\n",
       "      <td>8.023438</td>\n",
       "      <td>10.265625</td>\n",
       "      <td>9.281250</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.031250</td>\n",
       "      <td>16.265625</td>\n",
       "      <td>9.289062</td>\n",
       "      <td>9.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>chr11</td>\n",
       "      <td>102264619</td>\n",
       "      <td>102264638</td>\n",
       "      <td>-</td>\n",
       "      <td>0.064819</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.921875</td>\n",
       "      <td>8.015625</td>\n",
       "      <td>10.281250</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.937500</td>\n",
       "      <td>8.015625</td>\n",
       "      <td>10.281250</td>\n",
       "      <td>9.273438</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.195312</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>9.312500</td>\n",
       "      <td>9.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>chr9</td>\n",
       "      <td>51332680</td>\n",
       "      <td>51332699</td>\n",
       "      <td>-</td>\n",
       "      <td>0.065369</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.945312</td>\n",
       "      <td>8.101562</td>\n",
       "      <td>10.296875</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>8.929688</td>\n",
       "      <td>8.070312</td>\n",
       "      <td>10.281250</td>\n",
       "      <td>9.265625</td>\n",
       "      <td>16.609375</td>\n",
       "      <td>11.210938</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>9.281250</td>\n",
       "      <td>9.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows  106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  chrom      start        end strand  genomic_SCD  Pad_50_b0_SCD  \\\n",
       "0       0  chr12   35192359   35192378      -    53.656250      35.093750   \n",
       "1       1   chr8  102781112  102781131      -    53.500000      28.875000   \n",
       "2       2   chr5   49961991   49962010      -    53.312500      30.656250   \n",
       "3       3   chr9   26776356   26776375      -    53.125000      30.140625   \n",
       "4       4   chr9   51152589   51152608      -    53.062500      28.875000   \n",
       "5       5   chr8   58566264   58566283      +    52.875000      23.968750   \n",
       "6       6  chr12   40837731   40837750      +    52.843750      28.953125   \n",
       "7       7   chr8   36523116   36523135      -    52.500000      28.875000   \n",
       "8       8   chr6  101261721  101261740      -    52.500000      28.875000   \n",
       "9       9  chr11   57467954   57467973      -    52.375000      30.406250   \n",
       "10     10   chr4   70621534   70621553      -    52.281250      28.875000   \n",
       "11     11   chr2  101905952  101905971      +    52.250000      28.875000   \n",
       "12     12  chr16   13117402   13117421      +    51.937500      29.062500   \n",
       "13     13  chr13   19698902   19698921      +    51.937500      28.875000   \n",
       "14     14   chr9   63136044   63136063      +    51.750000      23.281250   \n",
       "15     15  chr12   92303369   92303388      +    51.625000      30.781250   \n",
       "16     16  chr11   31949597   31949616      -    51.562500      28.875000   \n",
       "17     17   chr9   49494116   49494135      +    51.187500      33.468750   \n",
       "18     18  chr12   17554295   17554314      +    51.187500      28.875000   \n",
       "19     19   chr9   88222169   88222188      -    51.156250      28.875000   \n",
       "20     20   chr7  139598311  139598330      +     0.058136       7.609375   \n",
       "21     21   chr8   45342919   45342938      +     0.058319       7.609375   \n",
       "22     22   chr2   27771666   27771685      -     0.058746       7.609375   \n",
       "23     23   chr1   35713888   35713907      +     0.059021       7.609375   \n",
       "24     24   chr9   51333610   51333629      -     0.059021       7.609375   \n",
       "25     25  chr11   57783694   57783713      -     0.059998       7.609375   \n",
       "26     26   chr6   94057464   94057483      +     0.060333       7.609375   \n",
       "27     27  chr16   23157002   23157021      -     0.060699       7.609375   \n",
       "28     28  chr11  102262359  102262378      -     0.061462       7.609375   \n",
       "29     29   chr9   71627181   71627200      +     0.062378       7.609375   \n",
       "30     30  chr13  109771756  109771775      +     0.062988       7.609375   \n",
       "31     31  chr11   32340269   32340288      +     0.063232       7.609375   \n",
       "32     32   chr2  107941165  107941184      -     0.063232       7.609375   \n",
       "33     33   chr7  143479908  143479927      +     0.063599       7.609375   \n",
       "34     34   chr8   88110358   88110377      +     0.064209       7.609375   \n",
       "35     35   chr2  160592247  160592266      +     0.064453       7.609375   \n",
       "36     36   chr5  147936524  147936543      +     0.064636       7.609375   \n",
       "37     37   chr2   31681471   31681490      +     0.064697       7.609375   \n",
       "38     38  chr11  102264619  102264638      -     0.064819       7.609375   \n",
       "39     39   chr9   51332680   51332699      -     0.065369       7.609375   \n",
       "\n",
       "    Pad_50_b1_SCD  Pad_50_b2_SCD  Pad_50_b3_SCD  ...  Pad_59_b0_SCD  \\\n",
       "0       34.843750      32.875000      35.093750  ...      35.531250   \n",
       "1       27.156250      27.765625      29.578125  ...      28.875000   \n",
       "2       28.390625      28.968750      32.781250  ...      31.953125   \n",
       "3       28.875000      29.093750      33.218750  ...      32.000000   \n",
       "4       26.437500      26.937500      28.953125  ...      28.875000   \n",
       "5       25.921875      22.187500      27.125000  ...      26.531250   \n",
       "6       27.062500      28.875000      32.500000  ...      29.078125   \n",
       "7       26.484375      28.750000      30.562500  ...      28.875000   \n",
       "8       28.078125      27.843750      30.218750  ...      28.875000   \n",
       "9       29.937500      30.500000      32.687500  ...      30.578125   \n",
       "10      26.578125      28.875000      32.531250  ...      28.906250   \n",
       "11      27.234375      27.953125      28.984375  ...      28.875000   \n",
       "12      26.750000      28.875000      31.312500  ...      29.156250   \n",
       "13      28.875000      27.750000      30.281250  ...      28.890625   \n",
       "14      20.578125      21.515625      26.234375  ...      23.718750   \n",
       "15      28.750000      28.875000      32.843750  ...      29.093750   \n",
       "16      26.296875      26.984375      28.875000  ...      28.875000   \n",
       "17      31.703125      31.437500      33.375000  ...      34.500000   \n",
       "18      24.375000      24.203125      28.875000  ...      28.875000   \n",
       "19      28.687500      26.656250      30.156250  ...      28.875000   \n",
       "20       8.882812       8.070312      10.328125  ...       7.609375   \n",
       "21       8.906250       8.023438      10.257812  ...       7.609375   \n",
       "22       8.929688       8.015625      10.265625  ...       7.609375   \n",
       "23       8.921875       8.062500      10.257812  ...       7.609375   \n",
       "24       8.914062       8.070312      10.265625  ...       7.609375   \n",
       "25       8.929688       7.953125      10.328125  ...       7.609375   \n",
       "26       8.898438       7.996094      10.273438  ...       7.609375   \n",
       "27       8.906250       8.007812      10.289062  ...       7.609375   \n",
       "28       8.890625       7.992188      10.289062  ...       7.609375   \n",
       "29       8.921875       8.054688      10.265625  ...       7.609375   \n",
       "30       8.898438       8.046875      10.281250  ...       7.609375   \n",
       "31       8.906250       7.976562      10.257812  ...       7.609375   \n",
       "32       8.898438       8.031250      10.281250  ...       7.609375   \n",
       "33       8.906250       8.000000      10.273438  ...       7.609375   \n",
       "34       8.906250       8.062500      10.281250  ...       7.609375   \n",
       "35       8.898438       8.039062      10.265625  ...       7.609375   \n",
       "36       8.882812       8.062500      10.289062  ...       7.609375   \n",
       "37       8.914062       8.039062      10.265625  ...       7.609375   \n",
       "38       8.921875       8.015625      10.281250  ...       7.609375   \n",
       "39       8.945312       8.101562      10.296875  ...       7.609375   \n",
       "\n",
       "    Pad_59_b1_SCD  Pad_59_b2_SCD  Pad_59_b3_SCD  Pad_59_b4_SCD  Pad_59_b5_SCD  \\\n",
       "0       34.843750      32.812500      35.093750      40.562500      43.125000   \n",
       "1       27.781250      28.875000      30.453125      32.062500      37.062500   \n",
       "2       29.000000      29.125000      31.234375      33.125000      37.062500   \n",
       "3       30.343750      29.546875      34.000000      35.031250      37.062500   \n",
       "4       26.609375      28.234375      29.296875      30.765625      37.062500   \n",
       "5       26.203125      24.875000      27.781250      28.875000      33.906250   \n",
       "6       28.125000      28.875000      33.062500      30.843750      37.062500   \n",
       "7       26.671875      28.875000      30.609375      30.671875      37.062500   \n",
       "8       28.656250      28.890625      30.125000      32.250000      37.062500   \n",
       "9       30.437500      30.546875      33.000000      35.218750      37.062500   \n",
       "10      26.812500      28.875000      32.062500      30.687500      37.062500   \n",
       "11      27.218750      28.515625      29.281250      31.390625      37.062500   \n",
       "12      26.859375      28.875000      32.062500      31.093750      37.062500   \n",
       "13      28.875000      28.328125      30.234375      34.218750      37.062500   \n",
       "14      23.078125      21.546875      26.265625      28.875000      32.562500   \n",
       "15      27.703125      28.875000      31.062500      30.671875      37.062500   \n",
       "16      28.093750      27.281250      28.953125      31.671875      37.062500   \n",
       "17      32.656250      31.750000      33.875000      37.781250      37.281250   \n",
       "18      25.890625      25.843750      28.906250      31.187500      37.062500   \n",
       "19      28.875000      27.687500      30.437500      33.000000      37.062500   \n",
       "20       8.882812       8.054688      10.320312       9.281250      16.609375   \n",
       "21       8.898438       8.007812      10.257812       9.320312      16.609375   \n",
       "22       8.906250       8.046875      10.296875       9.273438      16.609375   \n",
       "23       8.898438       8.085938      10.257812       9.218750      16.609375   \n",
       "24       8.906250       8.039062      10.257812       9.203125      16.609375   \n",
       "25       8.929688       7.972656      10.296875       9.320312      16.609375   \n",
       "26       8.890625       8.015625      10.273438       9.250000      16.609375   \n",
       "27       8.914062       8.007812      10.281250       9.312500      16.609375   \n",
       "28       8.890625       7.960938      10.296875       9.312500      16.609375   \n",
       "29       8.906250       8.046875      10.257812       9.234375      16.609375   \n",
       "30       8.882812       8.054688      10.281250       9.250000      16.609375   \n",
       "31       8.898438       7.968750      10.250000       9.234375      16.609375   \n",
       "32       8.906250       8.046875      10.281250       9.203125      16.609375   \n",
       "33       8.882812       7.953125      10.265625       9.289062      16.609375   \n",
       "34       8.898438       8.062500      10.265625       9.296875      16.609375   \n",
       "35       8.890625       8.101562      10.273438       9.250000      16.609375   \n",
       "36       8.882812       8.054688      10.328125       9.296875      16.609375   \n",
       "37       8.914062       8.023438      10.265625       9.281250      16.609375   \n",
       "38       8.937500       8.015625      10.281250       9.273438      16.609375   \n",
       "39       8.929688       8.070312      10.281250       9.265625      16.609375   \n",
       "\n",
       "    Pad_59_b6_SCD  Pad_59_b7_SCD  Pad_59_b8_SCD  Pad_59_b9_SCD  \n",
       "0       34.875000      46.812500      33.750000      34.843750  \n",
       "1       29.453125      38.218750      32.312500      28.875000  \n",
       "2       30.734375      39.343750      33.187500      28.937500  \n",
       "3       30.843750      41.968750      33.750000      29.718750  \n",
       "4       28.906250      37.187500      27.921875      28.875000  \n",
       "5       28.875000      35.500000      25.812500      26.640625  \n",
       "6       30.296875      41.468750      32.656250      28.921875  \n",
       "7       29.500000      38.562500      31.718750      28.875000  \n",
       "8       29.187500      37.812500      31.296875      28.875000  \n",
       "9       32.218750      43.937500      33.781250      30.546875  \n",
       "10      30.109375      40.937500      32.500000      28.875000  \n",
       "11      28.875000      36.562500      27.453125      28.875000  \n",
       "12      30.078125      40.312500      32.500000      28.875000  \n",
       "13      29.859375      37.562500      29.093750      28.875000  \n",
       "14      28.875000      33.281250      25.484375      23.375000  \n",
       "15      30.531250      38.375000      32.312500      28.875000  \n",
       "16      28.875000      37.156250      26.546875      28.875000  \n",
       "17      34.843750      44.125000      33.750000      30.687500  \n",
       "18      28.890625      37.125000      26.218750      28.875000  \n",
       "19      29.718750      38.000000      29.281250      28.875000  \n",
       "20      11.078125      16.250000       9.281250       9.125000  \n",
       "21      11.203125      16.281250       9.257812       9.117188  \n",
       "22      11.078125      16.281250       9.265625       9.125000  \n",
       "23      11.242188      16.265625       9.281250       9.125000  \n",
       "24      11.226562      16.281250       9.296875       9.117188  \n",
       "25      11.109375      16.281250       9.265625       9.125000  \n",
       "26      11.156250      16.281250       9.281250       9.117188  \n",
       "27      11.218750      16.265625       9.281250       9.125000  \n",
       "28      10.968750      16.250000       9.265625       9.125000  \n",
       "29      11.203125      16.265625       9.312500       9.117188  \n",
       "30      11.242188      16.281250       9.296875       9.125000  \n",
       "31      11.210938      16.296875       9.265625       9.117188  \n",
       "32      11.312500      16.250000       9.265625       9.117188  \n",
       "33      10.960938      16.250000       9.273438       9.125000  \n",
       "34      11.289062      16.281250       9.265625       9.117188  \n",
       "35      11.187500      16.281250       9.343750       9.117188  \n",
       "36      11.015625      16.250000       9.257812       9.125000  \n",
       "37      11.031250      16.265625       9.289062       9.117188  \n",
       "38      11.195312      16.281250       9.312500       9.117188  \n",
       "39      11.210938      16.281250       9.281250       9.125000  \n",
       "\n",
       "[40 rows x 106 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_padding(seq_coords_df, background_seqs, pad_list, orientation = \"divergent\", plotting=False, \n",
    "                     num_inserts=2, \n",
    "                     one_side_radius=100, \n",
    "                     motif_len=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f45bfb3-4e47-476f-8b7a-6a5ae5c6461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_coords_df.to_csv(\"./50-60pads_divergent.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f62dc58-fb57-4a4d-90d6-a5b719742422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea1fdaf-b366-4710-86dd-407752d716c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbce8d48-e351-4113-9dac-74bab11c5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offsets = []\n",
    "\n",
    "# print(seq_length//2)\n",
    "# print(seq_length//2 - multi_insert_length//2)\n",
    "# for i in range(num_inserts):\n",
    "#     offsets.append( seq_length//2 - multi_insert_length//2 + i * (multi_insert_length//2) + spacer)\n",
    "# print(offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2934dc2a-3033-475e-bb50-4cdb19698746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_inserts = []\n",
    "\n",
    "# # inserting only to the first background sequence\n",
    "# for background_seq in background_seqs:\n",
    "#     for i in seq_coords_df.index:\n",
    "#         seq_1hot = background_seq.copy()\n",
    "#         this_row = seq_coords_df.iloc[i]\n",
    "#         seq_1hot_CTCF_pad = dna_io.dna_1hot(genome_open.fetch(this_row.chrom, this_row.start-padding, this_row.end+padding).upper())\n",
    "#         if this_row.strand == '-': \n",
    "#             seq_1hot_CTCF_pad = dna_io.hot1_rc(seq_1hot_CTCF_pad)\n",
    "#         # print(this_row.strand, Seq(genome_open.fetch(this_row.chrom, this_row.start-padding, this_row.end+padding).upper()))\n",
    "#         for offset in offsets:\n",
    "#             seq_1hot[offset : offset + len(seq_1hot_CTCF_pad)] = seq_1hot_CTCF_pad\n",
    "#         all_inserts.append(seq_1hot)\n",
    "#         # print(seq_1hot[655241:655241+19] == seq_1hot[655260:655260+19])\n",
    "# all_inserts = np.array(all_inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b036662-db62-4b08-91a5-02b7bc42fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_inserts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bbff5eb-032c-4cc7-8d23-02cd997448db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = seqnn_model.predict(all_inserts, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fc34c18-5037-49c1-ab40-68b7a0dbc2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2aad89c-a765-465a-84f2-e9efdb515581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scd_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d52395e-71f8-4fb0-9f5d-ae6de751155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8*3,5*3))\n",
    "\n",
    "# target_ind = 0\n",
    "# vlim = .5\n",
    "# bin_mid = target_map_size//2\n",
    "# window = 50\n",
    "# for i in range(40):\n",
    "#     insert_pred = pred[i]\n",
    "#     print(i, np.sqrt( (insert_pred**2).sum(axis=0)))\n",
    "#     scd_score.append(np.sqrt( (insert_pred**2).sum(axis=0)  ).mean())\n",
    "    \n",
    "#     plt.subplot(8,5, i+1)\n",
    "#     im = plt.matshow(\n",
    "#             akita_utils.from_upper_triu(  \n",
    "#             insert_pred[:,target_ind], target_map_size,hic_diags),\n",
    "#             vmin=-1*vlim, vmax=vlim, fignum=False,cmap='RdBu_r')\n",
    "#     plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "#     plt.title('insert-scd: '+str(  np.sqrt( (insert_pred**2).sum(axis=0)  ).mean() ) \n",
    "#               ) \n",
    "#     #plt.axis([ bin_mid  - window,bin_mid+window,bin_mid-window, bin_mid+window])\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adcfe6c2-8003-432d-b192-01784e1ccceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(400):\n",
    "#     insert_pred = pred[i]\n",
    "#     # print(i, np.sqrt( (insert_pred**2).sum(axis=0)))\n",
    "#     scd_score.append(np.sqrt( (insert_pred**2).sum(axis=0)  ).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "809a9851-d552-42d7-ba10-855f8d275b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(scd_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6284f155-87cd-435b-9d20-b3712a2e24b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_scd_score = np.array(scd_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "047cabd8-10d7-4fc6-99c3-e10003265776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_scd_score[2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62db03a6-e994-47a6-b584-0cff82d28377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaped_np_scd_score = np_scd_score.reshape((10,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9db1526d-ab1b-4828-9fc1-5510421a01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaped_np_scd_score[:,31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c29a123-3770-435a-a94c-3660e5030fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaped_np_scd_score.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36ae8c01-58f8-435e-80b3-fe5427420f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_coords_df[f\"Pad{padding}_SCD\"] = scd_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed0a160f-14fc-4d84-ba0b-b51a38826b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_coords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e783107a-08b5-4a93-9102-fde4a73f2cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Basenji kernel",
   "language": "python",
   "name": "basenji_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
